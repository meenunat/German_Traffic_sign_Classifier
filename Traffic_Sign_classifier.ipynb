{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Space: YUV\n",
      "--------------------------------------------------------------------------------\n",
      "New Images for Random Testing\n",
      "--------------------------------------------------------------------------------\n",
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n",
      "Unique Signs:\n",
      "preprocessing completed\n",
      "Training...\n",
      "\n",
      "EPOCH 1 ..."
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.io.parsers import read_csv\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import exposure\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import math \n",
    "from math import ceil\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "class traffic_sign_classifier(object):\n",
    "    def __init__(self,rate=0.0008,epochs=5,keep_prob=1.0,batch_size=128,learning_curve=True,save_model=True,test_model=True,\n",
    "                 brightness=False,norm=True,rotation=False,new_image=True):\n",
    "        #gray=False,xyz=False,hsv=False,hls=False,lab=False,luv=False,ycrcb=False,yuv=False\n",
    "        #Input files for the classifier\n",
    "        #self.sign_index = read_csv(\"signnames.csv\").values[:, 1]\n",
    "        self.signnames = read_csv(\"signnames.csv\").values[:, 1]\n",
    "        self.training_file = \"input/train.p\"\n",
    "        self.validation_file= \"input/valid.p\"\n",
    "        self.testing_file = \"input/test.p\"\n",
    "        \n",
    "        #List for data\n",
    "        self.X_train = [] # Training Data\n",
    "        self.y_train = [] # Training labels\n",
    "        self.X_valid = [] # validation data \n",
    "        self.y_valid = [] # validation labels\n",
    "        self.X_test = [] # test data \n",
    "        self.y_test = [] # test labels \n",
    "        self.images_dir = []\n",
    "        #self.new_images = [] # random image test set from web       \n",
    "        self.X_new = []  # Ramdom image's test features \n",
    "        self.y_new = []  # Random image's test labels\n",
    "\n",
    "     \n",
    "        # Create dictionary for unique traffic signals\n",
    "        self.unique_signs_dict = {} # each classID is presented: total 43 classes\n",
    "        \n",
    "        #visualiization parameters\n",
    "        self.plot_row = 8 # row numbers\n",
    "        self.plot_col = 6 # column numbers\n",
    "        \n",
    "        #color\n",
    "        #self.name = name\n",
    "        #self.gray = gray\n",
    "        #self.xyz = xyz\n",
    "        #self.hsv = hsv\n",
    "        #self.hls = hls\n",
    "        #self.lab = lab\n",
    "        #self.luv = luv\n",
    "        #self.yuv = yuv\n",
    "        #self.ycrcb = ycrcb  \n",
    "\n",
    "              \n",
    "        #Other parameters\n",
    "        self.learning_curve = learning_curve\n",
    "        self.brightness = brightness\n",
    "        self.norm = norm\n",
    "        self.rotation = rotation\n",
    "        self.new_image = new_image\n",
    "        \n",
    "        #Loading Data\n",
    "        self.load_data()\n",
    "                \n",
    "        #Model Architecture Information\n",
    "        self.mu = 0\n",
    "        self.sigma = 0.1\n",
    "        # --> Convolution Layer1 \n",
    "        # Gray color space only 1-channel \n",
    "        self.conv1_shape_g = (5, 5, 1, 32) # Filter shape gray color space\n",
    "        self.conv1_shape = (5, 5, 3, 32) # Filter shape for color space\n",
    "        self.conv1_strides=[1, 1, 1, 1] # Convolution Layer1 Strides\n",
    "        # --> Pooling Layer1\n",
    "        self.conv1_pooling_ksize=[1, 2, 2, 1] # Kernel size\n",
    "        self.conv1_pooling_strides=[1, 2, 2, 1] # Pooling strides\n",
    "        # --> Convolution Layer2\n",
    "        self.conv2_shape = (5, 5, 32, 64) # Filter shape for color space\n",
    "        self.conv2_strides=[1, 1, 1, 1] #Convolution Layer2 Strides\n",
    "        # --> Pooling Layer2\n",
    "        self.conv2_pooling_ksize=[1, 2, 2, 1] # Kernel size\n",
    "        self.conv2_pooling_strides=[1, 2, 2, 1] # Pooling strides\n",
    "        # --> Dropout\n",
    "        self.keep_prob=keep_prob # Dropping 50% of the data\n",
    "        # --> Fully connected Layer1\n",
    "        self.fc1_shape = (1600, 540) # flattening the connections\n",
    "        # --> Fully connected Layer2\n",
    "        self.fc2_shape = (540, 190) # flattening the connections\n",
    "        # --> Fully connected Layer3\n",
    "        self.fc3_shape = (190,86)   # flattening the connections     \n",
    "        # --> Fully connected Layer4\n",
    "        self.fc4_shape = (86, self.n_classes) # flattening the connections         \n",
    "       \n",
    "        #Training Model Variables:\n",
    "        self.rate = rate\n",
    "        self.EPOCHS = epochs\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        \n",
    "        #Training Efficiency\n",
    "        self.save = save_model\n",
    "        self.test = test_model\n",
    " \n",
    "        # Training Pipeline Variables      \n",
    "        # Creating placeholder for y\n",
    "        self.y = tf.placeholder(tf.int32,(None)) \n",
    "        self.one_hot_y = tf.one_hot(self.y, self.n_classes)\n",
    "        \n",
    "        # Top prediction parameters\n",
    "        self.top_pred = [] # top predictions list\n",
    "        self.k = 5 # number of top predictions\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    def load_data(self):\n",
    "        with open(self.training_file, mode='rb') as f:\n",
    "            train = pickle.load(f)\n",
    "        with open(self.validation_file, mode='rb') as f:\n",
    "            valid = pickle.load(f)\n",
    "        with open(self.testing_file, mode='rb') as f:\n",
    "            test = pickle.load(f)\n",
    "            \n",
    "        self.X_train, self.y_train = train['features'], train['labels']\n",
    "        self.X_valid, self.y_valid = valid['features'], valid['labels']\n",
    "        self.X_test, self.y_test = test['features'], test['labels']\n",
    "        self.images_dir = sorted(glob.glob('./images/*.png'))\n",
    "        for path in self.images_dir:\n",
    "            new_feature_data = cv2.imread(path) \n",
    "            new_label_data = path.split('.')[0] \n",
    "            new_label_data = (new_label_data.split('_')[-1])\n",
    "            self.X_new.append(new_feature_data)\n",
    "            #self.y_new.append(int(new_label_data))\n",
    "            \n",
    "        #if(self.new_image):\n",
    "\n",
    "                    \n",
    "        ### Replace each question mark with the appropriate value. \n",
    "        ### Use python, pandas or numpy methods rather than hard coding the results\n",
    "        \n",
    "        # TODO: Number of training examples\n",
    "        self.n_train = self.y_train.shape[0]\n",
    "        \n",
    "        # TODO: Number of validation examples\n",
    "        self.n_validation = self.y_valid.shape[0]\n",
    "        \n",
    "        # TODO: Number of testing examples.\n",
    "        self.n_test = self.y_test.shape[0]\n",
    "        \n",
    "        # TODO: What's the shape of an traffic sign image?\n",
    "        #image_shape = X_train.shape[0]\n",
    "        self.image_shape = self.X_train[0].shape\n",
    "        \n",
    "        # TODO: How many unique classes/labels there are in the dataset.\n",
    "        self.unique_array, self.unique_indices, self.unique_counts = np.unique(self.y_train, return_inverse = False, return_index = True, return_counts = True)\n",
    "        self.n_classes = self.unique_array.shape[0]\n",
    "           \n",
    "    def plot_distribution(self):\n",
    "        plt.figure(figsize=(15,6))  \n",
    "        plt.title('{}'.format(\"German Traffic Signal Data Distribution\"))\n",
    "        plt.ylabel('{}'.format(\"Frequency\"))\n",
    "        plt.xlabel('{}'.format(\"Traffic Sign Labels\"))\n",
    "        plt.hist(self.y_train,bins=self.n_classes,facecolor='blue')\n",
    "        plt.grid(True)        \n",
    "        plt.show()        \n",
    "\n",
    "    def print_data_summary(self):\n",
    "        print(\"Number of training examples =\", self.n_train)\n",
    "        print(\"Number of validation examples =\", self.n_validation)\n",
    "        print(\"Number of testing examples =\", self.n_test)\n",
    "        print(\"Image data shape =\", self.image_shape)\n",
    "        print(\"Number of classes =\", self.n_classes)\n",
    "        \n",
    "        ### Data exploration visualization code goes here.\n",
    "        ### Feel free to use as many code cells as needed.\n",
    "        # Visualizations will be shown in the notebook.\n",
    "        #%matplotlib inline\n",
    "        \n",
    "    def unique_signs(self):\n",
    "        dict_len = len(np.unique(self.y_train))\n",
    "        for i in range(self.X_train.shape[0]):\n",
    "            if (len(self.unique_signs_dict) == dict_len):\n",
    "                return self.unique_signs_dict\n",
    "            else:\n",
    "                self.unique_signs_dict[self.y_train[i]] = self.X_train[i]\n",
    "                \n",
    "    def plot_image(self,image_data):\n",
    "        plt.figure(figsize=(2.5*self.plot_col,2.5*self.plot_row))  \n",
    "        for i in range(len(image_data)):\n",
    "            plt.subplot(self.plot_row,self.plot_col,i+1)\n",
    "            plt.imshow(image_data[i])\n",
    "            plt.text(0, 0, '{}: {}'.format(i, self.signnames[i]), color='k',backgroundcolor='gray', fontsize=9)   \n",
    "            plt.text(0, image_data[i].shape[0]-3, '{}'.format(image_data[i].shape), color='k',backgroundcolor='g', fontsize=9) \n",
    "        plt.show()\n",
    "        \n",
    "    def plot_top_prediction(self,cols=5):\n",
    "        print('-' * 80)\n",
    "        print('Top 5 Predictions')\n",
    "        print('-' * 80)\n",
    "        rows = int(len(self.top_pred.indices)/cols)\n",
    "        plt.figure(figsize=(3.5*cols,3.5*rows))\n",
    "        for i in range(rows):\n",
    "            #if ((rows%cols) > 0):\n",
    "            #    plt.subplot(rows+1,cols,i+1)\n",
    "            #else:\n",
    "            plt.subplot(rows+i,cols,i+1)\n",
    "            for j in range(self.k):\n",
    "                if (self.y_new[j] != top_pred.indices[j][0]):\n",
    "                    plt.title(\"Wrong Prediction: {} \".format(self.sign_index[top_pred.indices[i][j]], color='red'))\n",
    "                    plt.text(np.array(X[i]).shape[0]+3,5*(j+1),\"Prediction: ({:.2f}%) --> {}\".format(100*top_pred.values[i][j],self.sign_index[top_pred.indices[i][j]]))\n",
    "                else:\n",
    "                    plt.title(\"Right Prediction: {} \".format(self.sign_index[top_pred.indices[i][j]],color='blue'))\n",
    "                    plt.text(np.array(X[i]).shape[0]+3,5*(j+1),\"Prediction: ({:.2f}%) --> {}\".format(100*top_pred.values[i][j],self.sign_index[top_pred.indices[i][j]]))\n",
    "                        \n",
    "        #for i, (preds, probs, image) in enumerate(zip(top_5_pred, top_5_prob, new_images)):\n",
    "        #    plt.imshow(image)\n",
    "        #    plt.xticks([])\n",
    "        #    plt.yticks([])\n",
    "        #    plt.show()\n",
    "        #    for pred, prob in zip(preds.astype(int), probs):\n",
    "        #        sign_name = SIGN_NAMES[pred]\n",
    "        #        print('{:>5}: {:<50} ({:>14.10f}%)'.format(pred, sign_name, prob*100.0))\n",
    "        #    print('-' * 80)\n",
    "\n",
    "    def data_exploration(self):\n",
    "        for index, u_index, u_count in zip(range(0,3), self.unique_indices, self.unique_counts):\n",
    "            print(\"Data Exploration for ClassID: %i: %s\" %(index, self.signnames[index]))\n",
    "            fig = plt.figure(figsize = (6, 1))\n",
    "            fig.subplots_adjust(left = 0, right = 1, bottom = 0, top = 1, hspace = 0.1, wspace = 0.1)\n",
    "            random_indices = random.sample(range(u_index,u_index+u_count), 10)\n",
    "            for i in range(10):\n",
    "                axis = fig.add_subplot(1, 10, i + 1, xticks=[], yticks=[])\n",
    "                axis.imshow(self.X_train[random_indices[i]])\n",
    "            plt.show()\n",
    "            \n",
    "    def show_learning_curve(self,learning):\n",
    "        learning = np.array(learning)\n",
    "        epochs = learning[:,0]\n",
    "        train = learning[:,1]\n",
    "        valid = learning[:,2]\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.plot(epochs, train, label='train')\n",
    "        plt.plot(epochs, valid, label='validation')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.xticks(epochs)\n",
    "        plt.legend(loc='center right')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_new_image(self):\n",
    "        print('-' * 80)\n",
    "        print('New Images for Random Testing')\n",
    "        print('-' * 80)\n",
    "        plt.figure(figsize=(15,5))\n",
    "        for index, img in enumerate(self.X_new):\n",
    "            plt.subplot(2,ceil(len(self.images_dir)//2),index+1)\n",
    "            plt.imshow(img)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])    \n",
    "        plt.show()\n",
    "\n",
    "    ### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "    ### converting to grayscale, etc.\n",
    "    ### Feel free to use as many code cells as needed.\n",
    "    # Normalize images\n",
    "    def image_normalization(self,X):\n",
    "        return (X - X.mean())/X.std()\n",
    "        \n",
    "    # Rotating images\n",
    "    def rotate_image(self, image, angle):\n",
    "        if angle == 0:\n",
    "            return image\n",
    "        angle = np.random.uniform(-angle, angle)\n",
    "        rows, cols = image.shape[:2]\n",
    "        print(\"rows:\",rows,\"cols\",cols)\n",
    "        size = np.array(image).shape[:2]\n",
    "        print(\"rows:\",size)\n",
    "        center = cols/2, rows/2\n",
    "        scale = 1.0\n",
    "        rotation = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "        return (cv2.warpAffine(image, rotation, size))\n",
    "    \n",
    "    def brightness_change(self, image, ratio):\n",
    "        # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        brightness = np.float64(hsv[:, :, 2])\n",
    "        brightness = brightness * (1.0 + np.random.uniform(-ratio, ratio))\n",
    "        brightness[brightness>255] = 255\n",
    "        brightness[brightness<0] = 0\n",
    "        hsv[:, :, 2] = brightness\n",
    "        return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    # Image augmentation\n",
    "    def transform_image(self, x, name):\n",
    "        converters ={'Gray': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2GRAY)),\n",
    "              'HSV': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2HSV)),\n",
    "              'HLS': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2HLS)),\n",
    "              'Lab': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2Lab)),\n",
    "              'Luv': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2Luv)),\n",
    "              'XYZ': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2XYZ)),\n",
    "              'Yrb': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2YCrCb)),\n",
    "              'YUV': (cv2.cvtColor(x.astype(np.float32), cv2.COLOR_RGB2YUV))}\n",
    "        x = converters[name]\n",
    "        return x\n",
    "\n",
    "    \n",
    "    # preprocess the image color space\n",
    "    def preprocess_data(self,X,name):\n",
    "        image_list = []\n",
    "        \n",
    "        #Image Normalization\n",
    "        if (self.norm):\n",
    "            X = self.image_normalization(X) \n",
    "            \n",
    "        #Rotate image to overfit data    \n",
    "        #if(self.rotation):\n",
    "        #    angle = 10\n",
    "        #    X = self.rotate_image(X, angle)\n",
    "        #    pass\n",
    "        \n",
    "        #Increase brightness of image\n",
    "        #if (self.brightness):\n",
    "        #    ratio = 0.65\n",
    "        #    X = self.brightness_change(X, ratio)\n",
    "            \n",
    "        #Transfor color space\n",
    "        augmenter = lambda x: self.transform_image(x,name) \n",
    "        [image_list.append(augmenter(X[i])) for i in range(X.shape[0])]\n",
    "        if (name =='Gray'):\n",
    "            image_list = np.reshape(image_list,(-1,32,32,1))\n",
    "        else:\n",
    "            image_list = np.reshape(image_list,(-1,32,32,3))         \n",
    "        return image_list\n",
    "    ############################################################### \n",
    "        ### Define your architecture here.\n",
    "        ### Feel free to use as many code cells as needed.\n",
    "    def conv_layer(self,input_data,conv_shape_W,conv_strides, mu, sigma,padding_type):\n",
    "        conv_W = tf.Variable(tf.truncated_normal(shape=conv_shape_W, mean = mu, stddev = sigma))\n",
    "        conv_b = tf.Variable(tf.zeros(conv_shape_W[3]))\n",
    "        return (tf.nn.conv2d(input_data, conv_W, strides=conv_strides, padding=padding_type) + conv_b)\n",
    "                    \n",
    "    def fully_connected_layer(self,fc_input,fc_shape,mu,sigma):\n",
    "        fc_W = tf.Variable(tf.truncated_normal(shape=fc_shape, mean = mu, stddev = sigma))\n",
    "        fc_b = tf.Variable(tf.zeros(fc_shape[1]))\n",
    "        return (tf.matmul(fc_input, fc_W) + fc_b)\n",
    "\n",
    "        \n",
    "    def activation_layer(self,conv):\n",
    "        return (tf.nn.relu(conv))\n",
    "        \n",
    "    def pool_layer(self,conv,conv_pooling_ksize,conv_pooling_strides,padding_type):\n",
    "        return (tf.nn.max_pool(conv, ksize= conv_pooling_ksize, strides= conv_pooling_strides,padding=padding_type))\n",
    "\n",
    "    def LeNet(self,x,name):    \n",
    "        # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "        # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x12.\n",
    "        if(name == 'Gray'):\n",
    "            conv1_shape = self.conv1_shape_g\n",
    "        else:\n",
    "            conv1_shape = self.conv1_shape\n",
    "        conv1 = self.conv_layer(x,conv1_shape,self.conv1_strides,self.mu,self.sigma,'VALID')\n",
    "        # SOLUTION: Activation.\n",
    "        conv1 = self.activation_layer(conv1)\n",
    "        # SOLUTION: Pooling. Input = 28x28x16. Output = 14x14x16.\n",
    "        conv1 = self.pool_layer(conv1, self.conv1_pooling_ksize, self.conv1_pooling_strides,'VALID')\n",
    "        # SOLUTION: Layer 2: Convolutional. Output = 10x10x64.\n",
    "        conv2 = self.conv_layer(conv1,self.conv2_shape,self.conv2_strides,self.mu,self.sigma,'VALID')            \n",
    "        # SOLUTION: Activation.\n",
    "        conv2 = self.activation_layer(conv2)        \n",
    "        # SOLUTION: Pooling. Input = 10x10x64. Output = 5x5x64\n",
    "        conv2 = self.pool_layer(conv2, self.conv2_pooling_ksize, self.conv2_pooling_strides,'VALID')\n",
    "        # SOLUTION: Flatten. Input = 5x5x64. Output = 1600.\n",
    "        fc0   = flatten(conv2)\n",
    "        # SOLUTION: Layer 3: Fully Connected. Input = 1600. Output = 960.\n",
    "        fc1 = self.fully_connected_layer(fc0,self.fc1_shape,self.mu,self.sigma)\n",
    "        # SOLUTION: Activation.\n",
    "        fc1    = self.activation_layer(fc1)\n",
    "        # SOLUTION: Layer 4: Fully Connected. Input = 960. Output = 280.\n",
    "        fc2 = self.fully_connected_layer(fc1,self.fc2_shape,self.mu,self.sigma)\n",
    "        # SOLUTION: Activation.\n",
    "        fc2 = self.activation_layer(fc2)\n",
    "        # SOLUTION: Layer 5: Fully Connected. Input = 280. Output = 90.\n",
    "        #logits = self.fully_connected_layer(fc2,self.fc3_shape,self.mu,self.sigma)\n",
    "        fc3 = self.fully_connected_layer(fc2,self.fc3_shape,self.mu,self.sigma)\n",
    "        # SOLUTION: Activation.\n",
    "        fc3    = self.activation_layer(fc3)\n",
    "        # SOLUTION: Layer 6: Fully Connected. Input = 90. Output = 43.\n",
    "        logits = self.fully_connected_layer(fc3,self.fc4_shape,self.mu,self.sigma)            \n",
    "        return logits\n",
    "\n",
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images.\n",
    "\n",
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed.\n",
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "\n",
    "    # Training model and testing\n",
    "    def training_pipeline(self,name):\n",
    "        # Creating place holder for X\n",
    "        #    Gray color space has only 1 channel\n",
    "        #    Color Space has 3 channels\n",
    "        if (name =='Gray'): \n",
    "            self.X = tf.placeholder(tf.float32, (None, self.X_test.shape[1], self.X_test.shape[2], 1)) \n",
    "        else: \n",
    "            self.X = tf.placeholder(tf.float32, (None, self.X_test.shape[1], self.X_test.shape[2], 3)) # Creating placeholder for X\n",
    "        logits = self.LeNet(self.X,name)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=self.one_hot_y,logits=logits )\n",
    "        loss_operation = tf.reduce_mean(cross_entropy)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = self.rate)\n",
    "        training_operation = optimizer.minimize(loss_operation)\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(self.one_hot_y, 1))\n",
    "        accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        y_pred = tf.nn.softmax(logits)\n",
    "        pred = tf.nn.top_k(y_pred,k=self.k)\n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "        def evaluate(self,X_data, y_data):\n",
    "            num_examples = len(X_data)\n",
    "            total_accuracy = 0\n",
    "            sess = tf.get_default_session()\n",
    "            for offset in range(0, num_examples, self.BATCH_SIZE):\n",
    "                batch_x, batch_y = X_data[offset:offset+self.BATCH_SIZE], y_data[offset:offset+self.BATCH_SIZE]\n",
    "                accuracy = sess.run(accuracy_operation, feed_dict={self.X: batch_x, self.y: batch_y})\n",
    "                total_accuracy += (accuracy * len(batch_x))\n",
    "            return total_accuracy / num_examples\n",
    "\n",
    "        def evaluate_model_with_new_img(self):\n",
    "            with tf.Session() as sess:\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "                feed_dict = {self.X: self.X_new, self.y: self.y_new}\n",
    "                self.top_pred = sess.run(pred, feed_dict=feed_dict)\n",
    "                plot_top_prediction()\n",
    "                #print(top_pred.values)\n",
    "                #print(top_pred.indices)                      \n",
    "        \n",
    "        def evaluate_model(self):\n",
    "            with tf.Session() as sess:\n",
    "                saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "                test_accuracy = evaluate(self,self.X_test, self.y_test)\n",
    "                print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "      \n",
    "        def training_model(self):\n",
    "            learning=[]\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                num_examples = len(self.X_train)\n",
    "                \n",
    "                print(\"Training...\")\n",
    "                print()\n",
    "                for i in range(self.EPOCHS):\n",
    "                    self.X_train, self.y_train = shuffle(self.X_train, self.y_train)\n",
    "                    for offset in range(0, num_examples, self.BATCH_SIZE):\n",
    "                        end = offset + self.BATCH_SIZE\n",
    "                        batch_x, batch_y = self.X_train[offset:end], self.y_train[offset:end]\n",
    "                        sess.run(training_operation, feed_dict={self.X: batch_x, self.y: batch_y})\n",
    "                    \n",
    "                    training_accuracy = evaluate(self,self.X_train, self.y_train)    \n",
    "                    validation_accuracy = evaluate(self,self.X_valid, self.y_valid)\n",
    "                    learning.append([i+1,training_accuracy,validation_accuracy])\n",
    "                    print(\"EPOCH {} ...\".format(i+1))\n",
    "                    print(\"Training Accuracy = {:.3f}\".format(training_accuracy))                        \n",
    "                    print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "                    print()\n",
    "                if (self.save):    \n",
    "                    saver.save(sess, './lenet')\n",
    "                    print(\"Model saved\")\n",
    "                if (self.learning_curve):\n",
    "                    self.show_learning_curve(learning)\n",
    "                if (self.test):\n",
    "                    print(\"evaluating Test Data...\")\n",
    "                    evaluate_model(self)\n",
    "                if (self.new_image):\n",
    "                    plot_new_image()\n",
    "                    print(\"evaluating New Data...\")\n",
    "                    evaluate_model_with_new_img(self)\n",
    "            \n",
    "        return training_model(self)\n",
    "        \n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")\n",
    "            \n",
    "#tsc = traffic_sign_classifier()\n",
    "#tsc.print_data_summary()\n",
    "#tsc.plot_distribution()\n",
    "#unique_signs_dict = tsc.unique_signs()\n",
    "#print(\"Unique Signs:\")\n",
    "#tsc.plot_image(unique_signs_dict)\n",
    "#tsc.data_exploration()\n",
    "#tsc.X_train = tsc.preprocessing(tsc.X_train)\n",
    "#######################################################################\n",
    "#color =['Gray','HSV', 'HLS','Lab', 'Luv', 'XYZ', 'Yrb','YUV']\n",
    "color = ['YUV']\n",
    "for name in color:\n",
    "    print('Color Space: {}'.format(name))\n",
    "    tsc = traffic_sign_classifier()\n",
    "    tsc.print_data_summary()\n",
    "    #tsc.plot_distribution()\n",
    "    unique_signs_dict = tsc.unique_signs()\n",
    "    print(\"Unique Signs:\")\n",
    "    #tsc.plot_image(unique_signs_dict)\n",
    "    #tsc.data_exploration()\n",
    "    tsc.X_train = tsc.preprocess_data(tsc.X_train,name)\n",
    "    tsc.X_valid = tsc.preprocess_data(tsc.X_valid,name)\n",
    "    tsc.X_test = tsc.preprocess_data(tsc.X_test,name)\n",
    "    print(\"preprocessing completed\")\n",
    "    tsc.training_pipeline(name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
